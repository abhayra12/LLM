{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5b3cad-695c-4178-81c5-eabea2d3480f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0812dbe5-0957-4764-aa9c-5f30220871ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e79d1ad-714d-47c0-8a96-c6121abfeb1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21ea3e9-7635-4afa-b10f-4435f999f5fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181dcdc-a583-4c39-9f9e-fbcdb8e97e06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8922e-cbc5-49f4-871f-24f1e1cc71ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-4o',\n",
    "    messages = [{\"role\": \"user\", \"content\":\"is it too late to join the course?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c71252-3f8c-4cff-b3c5-9041fbc0da54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52e840f-31ab-495f-8459-1f9d4299f792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df77d3775324b4491d2f37447c75282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()  # You will be prompted for your HF key, which will then be saved locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2e25b-3ac3-45bc-bb60-0d86c3aea955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Hugging Face client (similar to OpenAI)\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "client = ChatHuggingFace(llm=llm, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b80fa1c-4cc3-4a17-9fe1-c32d607f60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I'd be happy to help, but I don't have any information about a specific course. Can you please provide more context or details about the course you're interested in? Such as:\n",
      "\n",
      "* What type of course is it (online, offline, university, etc.)?\n",
      "* What's the name of the course?\n",
      "* What's the deadline for joining the course?\n",
      "\n",
      "This will help me provide you with a more accurate answer about whether it's too late to join the course.\n"
     ]
    }
   ],
   "source": [
    "# Use the same message format as OpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Method 1: Using LangChain message objects (recommended)\n",
    "messages = [\n",
    "    HumanMessage(content=\"is it too late to join the course?\")\n",
    "]\n",
    "\n",
    "# Get response (similar to OpenAI's client.chat.completions.create)\n",
    "response = client.invoke(messages)\n",
    "\n",
    "# Access the response content (like OpenAI's response.choices[0].message.content)\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed01b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple wrapper class to make it work exactly like OpenAI\n",
    "class HuggingFaceClient:\n",
    "    def __init__(self, client):\n",
    "        self.chat = ChatCompletions(client)\n",
    "\n",
    "class ChatCompletions:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def create(self, model=None, messages=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Mimics OpenAI's chat.completions.create() method\n",
    "        messages format: [{\"role\": \"user\", \"content\": \"your message\"}]\n",
    "        \"\"\"\n",
    "        from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "        \n",
    "        # Convert OpenAI format to LangChain format\n",
    "        langchain_messages = []\n",
    "        for msg in messages:\n",
    "            role = msg.get(\"role\")\n",
    "            content = msg.get(\"content\")\n",
    "            \n",
    "            if role == \"system\":\n",
    "                langchain_messages.append(SystemMessage(content=content))\n",
    "            elif role == \"user\":\n",
    "                langchain_messages.append(HumanMessage(content=content))\n",
    "            elif role == \"assistant\":\n",
    "                langchain_messages.append(AIMessage(content=content))\n",
    "        \n",
    "        # Get response from Hugging Face\n",
    "        ai_response = self.client.invoke(langchain_messages)\n",
    "        \n",
    "        # Return an object that mimics OpenAI's response structure\n",
    "        class Response:\n",
    "            def __init__(self, content):\n",
    "                self.choices = [type('obj', (object,), {\n",
    "                    'message': type('obj', (object,), {\n",
    "                        'content': content\n",
    "                    })()\n",
    "                })()]\n",
    "        \n",
    "        return Response(ai_response.content)\n",
    "\n",
    "# Wrap the Hugging Face client\n",
    "hf_client = HuggingFaceClient(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb7d18f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI-style response: I'd be happy to help you with that, but I don't have any information about a specific course you're referring to. Could you please provide more context or details about the course you're interested in joining, such as:\n",
      "\n",
      "* The name of the course\n",
      "* The type of course (e.g. online, in-person, university, etc.)\n",
      "* The deadline for joining the course\n",
      "* Any relevant details about the course (e.g. prerequisites, requirements, etc.)\n",
      "\n",
      "Once I have this information, I'll do my best to provide you with an answer about whether it's too late to join the course.\n"
     ]
    }
   ],
   "source": [
    "# Now use it EXACTLY like OpenAI API!\n",
    "response = hf_client.chat.create(\n",
    "    model='microsoft/Phi-3-mini-4k-instruct',  # model param is optional here\n",
    "    messages=[{\"role\": \"user\", \"content\": \"is it too late to join the course?\"}]\n",
    ")\n",
    "\n",
    "# Access response the same way as OpenAI\n",
    "print(\"OpenAI-style response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f6266f8-aa80-4701-8ae5-738445c6ddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help you, but I don't have any information about a specific course you're referring to. Could you please provide more context or details about the course you're interested in joining? That way, I can better understand your situation and provide a more accurate response.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741fcc31-1a5b-4c5d-9ce0-28a17fffca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
